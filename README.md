Recon Automation Workflow

This project integrates multiple reconnaissance, crawling, and scanning tools into a single automated workflow.
The goal is to collect subdomains, crawl endpoints, extract JavaScript routes, detect secrets, run vulnerability scans, and gather external intelligence â€” all while filtering noise and reducing false positives.

ğŸš€ Integrated Tools
ğŸ” Discovery & Enumeration

subfinder â€” passive subdomain discovery

httpx â€” live host probing, status codes, redirects, content length

waybackurls â€” historical URL extraction

ğŸŒ Crawling & URL Collection

katana â€” high-performance crawler with JavaScript awareness

gospider â€” supplementary crawler for deeper traversal

ğŸ§© JavaScript Analysis

LinkFinder â€” extract JS endpoints

SecretFinder â€” detect secrets, API keys, tokens inside JS files

ğŸ›¡ Security Scanning

Nuclei â€” vulnerability scanning (background execution supported)

ParamSpider â€” parameter discovery for SSRF/XSS/open redirect vectors

CIRT.sh â€” configuration and security checks

ğŸ§ª Fuzzing

ffuf â€” directory and file fuzzing for hidden paths

ğŸ“¡ External Intelligence

SecurityTrails API â€” domain intel & subdomain enumeration

Shodan API â€” internet-facing service discovery

Censys API â€” host fingerprinting and network enumeration

VirusTotal API â€” domain reputation and threat enrichment

ğŸ“ What the Workflow Produces

Subdomain lists

Active hosts (httpx)

Crawled URLs + historical URLs

Filtered endpoints (API, login, admin, config, etc.)

JS endpoints + secrets

Fuzzing results (ffuf)

Vulnerability scan results (Nuclei)

External intelligence reports

False positives are reduced using response-length and content-fingerprint filtering.

ğŸ¯ Goal

To generate clean, structured, and actionable recon data that can be used directly for penetration testing, bug bounty, or continuous asset monitoring.
